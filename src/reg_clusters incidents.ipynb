{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:28.571262Z",
     "start_time": "2024-10-17T08:19:28.565106Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL.ImageColor import colormap\n",
    "from cartopy import crs as ccrs\n",
    "from cartopy import feature as cfeature\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "#from joblib import Parallel, delayed\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:28.710883Z",
     "start_time": "2024-10-17T08:19:28.680773Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "equipment = pd.read_csv('../data/equipment.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:28.773487Z",
     "start_time": "2024-10-17T08:19:28.758524Z"
    }
   },
   "outputs": [],
   "source": [
    "equipment.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:28.837461Z",
     "start_time": "2024-10-17T08:19:28.833641Z"
    }
   },
   "outputs": [],
   "source": [
    "#equipment.drop(columns=['Ist'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:28.895920Z",
     "start_time": "2024-10-17T08:19:28.883874Z"
    }
   },
   "outputs": [],
   "source": [
    "equipment['Postleitzahl'] = equipment['Postleitzahl'].astype(str)\n",
    "\n",
    "def expand_plz(postleitzahl: str) -> str:\n",
    "    if len(postleitzahl) < 5:\n",
    "        return '0' + postleitzahl\n",
    "    return postleitzahl\n",
    "\n",
    "equipment['Postleitzahl'] = equipment['Postleitzahl'].apply(expand_plz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:28.959856Z",
     "start_time": "2024-10-17T08:19:28.945719Z"
    }
   },
   "outputs": [],
   "source": [
    "equipment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:29.058819Z",
     "start_time": "2024-10-17T08:19:29.036662Z"
    }
   },
   "outputs": [],
   "source": [
    "# CSV-Datei mit Postleitzahlen und Koordinaten einlesen\n",
    "plz_koordinaten = {}\n",
    "with open('../data/plz_geocoord.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    next(reader)  # Überspringe die Kopfzeile\n",
    "    for rows in reader:\n",
    "        plz, lat, lon = rows\n",
    "        plz_koordinaten[plz] = (float(lat), float(lon))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:30.746965Z",
     "start_time": "2024-10-17T08:19:29.183933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Funktion zum Nachschlagen der Koordinaten\n",
    "def get_coordinates(postleitzahl: str) -> Tuple[float, float]:\n",
    "    return plz_koordinaten.get(postleitzahl, (np.nan, np.nan))\n",
    "\n",
    "# Neue Spalten für Latitude und Longitude hinzufügen\n",
    "equipment[['lat', 'lon']] = equipment['Postleitzahl'].apply(get_coordinates).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:30.778690Z",
     "start_time": "2024-10-17T08:19:30.764145Z"
    }
   },
   "outputs": [],
   "source": [
    "equipment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:30.882575Z",
     "start_time": "2024-10-17T08:19:30.870260Z"
    }
   },
   "outputs": [],
   "source": [
    "equipment.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:31.046373Z",
     "start_time": "2024-10-17T08:19:31.034337Z"
    }
   },
   "outputs": [],
   "source": [
    "equipment.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:31.201745Z",
     "start_time": "2024-10-17T08:19:31.195763Z"
    }
   },
   "outputs": [],
   "source": [
    "equipment.rename({'Anzahl Sätze': 'incident_count'}, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:31.395488Z",
     "start_time": "2024-10-17T08:19:31.278227Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../data/equipment.csv', mode='w') as outfile:\n",
    "    equipment.to_csv(outfile, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:38.629516Z",
     "start_time": "2024-10-17T08:19:31.445289Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Contour graph\n",
    "lat_values = np.linspace(equipment['lat'].min(), equipment['lat'].max(), 100)\n",
    "lon_values = np.linspace(equipment['lon'].min(), equipment['lon'].max(), 100)\n",
    "lat_grid, lon_grid = np.meshgrid(lat_values, lon_values)\n",
    "\n",
    "# Interpolate Incident values for the grid (for visualization purposes)\n",
    "incident_grid = griddata((equipment['lat'], equipment['lon']), equipment['incident_count'], (lat_grid, lon_grid), method='linear')\n",
    "\n",
    "plt.contourf(lon_grid, lat_grid, incident_grid, cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:39.097787Z",
     "start_time": "2024-10-17T08:19:38.688337Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,11.8/2))\n",
    "plt.scatter(equipment[\"lon\"], equipment[\"lat\"], s=5)\n",
    "plt.savefig(\"../plots/equipment_scatter.svg\", format='svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:39.198820Z",
     "start_time": "2024-10-17T08:19:39.183736Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = equipment[[\"Equipment\", \"lat\", \"lon\", \"incident_count\"]].copy()\n",
    "X_train.dropna(axis=0, inplace=True)\n",
    "\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:39.305490Z",
     "start_time": "2024-10-17T08:19:39.297701Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.round(X_train.max(), 2), \"\\n\", np.round(X_train.min(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:39.465155Z",
     "start_time": "2024-10-17T08:19:39.460161Z"
    }
   },
   "outputs": [],
   "source": [
    "# Separate the 'equipment_id' column\n",
    "equipment_id = X_train['Equipment']\n",
    "features = X_train.drop(columns=['Equipment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:39.529400Z",
     "start_time": "2024-10-17T08:19:39.517434Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scale only the feature columns\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "features_scaled = pd.DataFrame(features_scaled, columns=features.columns)\n",
    "\n",
    "# Combine the scaled features with the 'equipment_id' column\n",
    "X_train_scaled = pd.concat([equipment_id.reset_index(drop=True), features_scaled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:39.589972Z",
     "start_time": "2024-10-17T08:19:39.584715Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "eps_values = np.arange(0.5, 2, 0.1)\n",
    "min_samples_values = range(75, 200, 10)\n",
    "\n",
    "print(\"Number of variations to test\", len(eps_values) * len(min_samples_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:39.646103Z",
     "start_time": "2024-10-17T08:19:39.640207Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_dbscan(eps: int, min_samples: int, x: pd.DataFrame) -> Tuple[int, int, float, int]:\n",
    "    dbscan_gs = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    labels_gs = dbscan_gs.fit_predict(x)\n",
    "    \n",
    "    # Silhouette Score requires at least 2 clusters, however, 2 clusters is not useful for our case\n",
    "    if len(set(labels_gs)) > 2:\n",
    "        score = silhouette_score(x, labels_gs)\n",
    "    else:\n",
    "        score = -1  # Invalid score if less than 2 clusters are found\n",
    "    \n",
    "    return eps, min_samples, score, len(set(labels_gs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:39.695375Z",
     "start_time": "2024-10-17T08:19:39.690396Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Perform parallel grid search\n",
    "# results = Parallel(n_jobs=-1)(delayed(evaluate_dbscan)(eps, min_samples, X_train[[\"lat\", \"lon\", \"weather_score\"]])\n",
    "#                               for eps in eps_values\n",
    "#                               for min_samples in min_samples_values)\n",
    "\n",
    "# # Convert results to a DataFrame for easier analysis\n",
    "# results_df = pd.DataFrame(results, columns=['eps', 'min_samples', 'score', 'n_clusters'])\n",
    "\n",
    "# # Display results\n",
    "# print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:39.748158Z",
     "start_time": "2024-10-17T08:19:39.743415Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Run DBSCAN\n",
    "# # Identify the best combination of parameters\n",
    "# best_result = results_df.loc[results_df['score'].idxmax()]\n",
    "# print(best_result)\n",
    "\n",
    "# dbscan = DBSCAN(eps=best_result[\"eps\"], min_samples=int(best_result[\"min_samples\"]))\n",
    "# # dbscan = DBSCAN(eps=0.3, min_samples=75)\n",
    "# labels = dbscan.fit_predict(X_train[['lat', 'lon', 'weather_score']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:39.798838Z",
     "start_time": "2024-10-17T08:19:39.793737Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# # Define the parameter grid\n",
    "# n_clusters_values = range(2, 10)\n",
    "\n",
    "# def evaluate_kmeans(n_clusters: int, X: pd.DataFrame) -> Tuple[int, float]:\n",
    "#     kmeans = KMeans(n_clusters=n_clusters)\n",
    "#     kmeans.fit(X)\n",
    "#     labels = kmeans.predict(X)\n",
    "#     score = silhouette_score(X, labels)\n",
    "#     return (n_clusters, score)\n",
    "\n",
    "# # Perform parallel grid search\n",
    "# results = Parallel(n_jobs=-1)(delayed(evaluate_kmeans)(n_clusters, X_train[[\"lat\", \"lon\", \"weather_score\"]])\n",
    "#                               for n_clusters in n_clusters_values)\n",
    "\n",
    "# # Convert results to a DataFrame for easier analysis\n",
    "# results_df = pd.DataFrame(results, columns=['n_clusters', 'score'])\n",
    "\n",
    "# # Display results\n",
    "# print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:39.991758Z",
     "start_time": "2024-10-17T08:19:39.839241Z"
    }
   },
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.25, min_samples=75)\n",
    "labels = dbscan.fit_predict(X_train_scaled[['lat', 'lon', 'incident_count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:40.041337Z",
     "start_time": "2024-10-17T08:19:40.033267Z"
    }
   },
   "outputs": [],
   "source": [
    "num_clusters = len(set(labels) - {-1})\n",
    "\n",
    "print(f\"Number of clusters: {num_clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:40.097018Z",
     "start_time": "2024-10-17T08:19:40.084958Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_scaled.loc[:, 'cluster'] = labels\n",
    "\n",
    "# Ensure 'Equipment' is of the same type in both DataFrames\n",
    "X_train['Equipment'] = X_train['Equipment'].astype(int)\n",
    "X_train_scaled['Equipment'] = X_train_scaled['Equipment'].astype(int)\n",
    "\n",
    "X_train = X_train.merge(X_train_scaled[['Equipment', 'cluster']], on='Equipment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:40.404839Z",
     "start_time": "2024-10-17T08:19:40.170633Z"
    }
   },
   "outputs": [],
   "source": [
    "noise_data = X_train[X_train['cluster'] == -1]\n",
    "non_noise_data = X_train[X_train['cluster'] != -1]\n",
    "\n",
    "# Create a 3D scatter plot using Plotly Graph Objects\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add trace for non-noise clusters\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=non_noise_data['lon'],\n",
    "    y=non_noise_data['lat'],\n",
    "    z=non_noise_data['incident_count'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=8,\n",
    "        color=non_noise_data['cluster'],  # Color by cluster\n",
    "        colorscale='Viridis',              # Color scale\n",
    "        opacity=0.8,\n",
    "        colorbar=dict(title='Cluster')\n",
    "    ),\n",
    "    text=non_noise_data['incident_count'],  # Hover text\n",
    "    hovertemplate='<b>Incident count:</b> %{text}<br><b>Lat:</b> %{y}<br><b>Lon:</b> %{x}'\n",
    "))\n",
    "\n",
    "# Add trace for noise cluster\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=noise_data['lon'],\n",
    "    y=noise_data['lat'],\n",
    "    z=noise_data['incident_count'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=8,\n",
    "        color='purple',  # Color for noise points\n",
    "        opacity=0.01,\n",
    "    ),\n",
    "    text=noise_data['incident_count'],  # Hover text\n",
    "    hovertemplate='<b>Incident count:</b> %{text}<br><b>Lat:</b> %{y}<br><b>Lon:</b> %{x}'\n",
    "))\n",
    "\n",
    "# Update layout for better visualization\n",
    "fig.update_layout(\n",
    "    title='3D Scatter Plot of Equipment Clusters in Germany',\n",
    "    scene=dict(\n",
    "        xaxis=dict(title='Longitude'),\n",
    "        yaxis=dict(title='Latitude'),\n",
    "        zaxis=dict(title='Incident count'),\n",
    "        aspectmode='cube'  # Ensure aspect ratio is equal\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Save the plot as an HTML file\n",
    "fig.write_html('../plots/clusters_incidents.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:40.499379Z",
     "start_time": "2024-10-17T08:19:40.484166Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate centroid of each cluster\n",
    "cluster_centers = X_train.groupby('cluster')[['lat', 'lon', 'incident_count']].mean().reset_index()\n",
    "\n",
    "reduce_maintenance = []\n",
    "increase_maintenance = []\n",
    "\n",
    "for centroid in cluster_centers.itertuples():\n",
    "    print(centroid)\n",
    "    if centroid.cluster == -1:\n",
    "        continue\n",
    "    if centroid.incident_count >= 5:\n",
    "        increase_maintenance.append(centroid)\n",
    "    elif centroid.incident_count < 5:\n",
    "        reduce_maintenance.append(centroid)\n",
    "\n",
    "reduce_maintenance = pd.DataFrame(reduce_maintenance)\n",
    "increase_maintenance = pd.DataFrame(increase_maintenance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:40.597553Z",
     "start_time": "2024-10-17T08:19:40.585331Z"
    }
   },
   "outputs": [],
   "source": [
    "reduce_maintenance.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:40.835372Z",
     "start_time": "2024-10-17T08:19:40.684904Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a 3D scatter plot using Plotly Graph Objects\n",
    "fig = go.Figure()\n",
    "\n",
    "reduce_maintenance_equipment = X_train[X_train['cluster'].isin(reduce_maintenance['cluster'])]\n",
    "increase_maintenance_equipment = X_train[X_train['cluster'].isin(increase_maintenance['cluster'])]\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=reduce_maintenance_equipment['lon'],\n",
    "    y=reduce_maintenance_equipment['lat'],\n",
    "    z=reduce_maintenance_equipment['incident_count'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=8,\n",
    "        color='green',\n",
    "        colorscale='Viridis',              # Color scale\n",
    "        opacity=0.8,\n",
    "        colorbar=dict(title='Cluster')\n",
    "    ),\n",
    "    text=reduce_maintenance_equipment['incident_count'],  # Hover text\n",
    "    hovertemplate='<b>Incident count:</b> %{text}<br><b>Lat:</b> %{y}<br><b>Lon:</b> %{x}'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=increase_maintenance_equipment['lon'],\n",
    "    y=increase_maintenance_equipment['lat'],\n",
    "    z=increase_maintenance_equipment['incident_count'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=8,\n",
    "        color='red',\n",
    "        colorscale='Viridis',              # Color scale\n",
    "        opacity=0.8,\n",
    "        colorbar=dict(title='Cluster')\n",
    "    ),\n",
    "    text=increase_maintenance_equipment['incident_count'],  # Hover text\n",
    "    hovertemplate='<b>Incident count:</b> %{text}<br><b>Lat:</b> %{y}<br><b>Lon:</b> %{x}'\n",
    "))\n",
    "\n",
    "\n",
    "# Update layout for better visualization\n",
    "fig.update_layout(\n",
    "    title='3D Scatter Plot of Equipment Clusters in Germany',\n",
    "    scene=dict(\n",
    "        xaxis=dict(title='Longitude'),\n",
    "        yaxis=dict(title='Latitude'),\n",
    "        zaxis=dict(title='Incident count'),\n",
    "        aspectmode='cube'  # Ensure aspect ratio is equal\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Save the plot as an HTML file\n",
    "fig.write_html('../plots/result_incidents.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:19:42.436625Z",
     "start_time": "2024-10-17T08:19:40.911418Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assign colors\n",
    "increase_maintenance_equipment.loc[:, 'color'] = 'red'\n",
    "reduce_maintenance_equipment.loc[:, 'color'] = 'green'\n",
    "\n",
    "combined = pd.concat([reduce_maintenance_equipment, increase_maintenance_equipment])\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "# Add geographical features\n",
    "ax.add_feature(cfeature.BORDERS, linestyle='-')\n",
    "ax.add_feature(cfeature.LAND, facecolor='white')\n",
    "ax.add_feature(cfeature.OCEAN, facecolor='lightblue')\n",
    "ax.add_feature(cfeature.COASTLINE, zorder=5)\n",
    "\n",
    "# Plot data points\n",
    "for color, group in combined.groupby('color'):\n",
    "    print(f\"Plotting color: {color} with {len(group)} points\")  # Debugging statement\n",
    "    ax.scatter(group['lon'], group['lat'], color=color, s=100, alpha=0.7, transform=ccrs.PlateCarree())\n",
    "\n",
    "# Set plot title and extent\n",
    "ax.set_title('Equipment Clusters in Germany')\n",
    "ax.set_extent([5, 15, 47, 55], crs=ccrs.PlateCarree())\n",
    "\n",
    "# Add legend\n",
    "ax.legend(['Reduce Maintenance', 'Increase Maintenance'], loc='upper left')\n",
    "\n",
    "# Save the plot as an image\n",
    "plt.savefig('../plots/cluster_plot_incidents.svg', bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
